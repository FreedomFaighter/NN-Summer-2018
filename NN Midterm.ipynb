{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Midterm\n",
    "    by Brian Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##First we import our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "filename = 'midterm_data.csv'\n",
    "head = ['X1','X2','Class']\n",
    "fptr = open(filename,'w', newline='')\n",
    "writer = csv.writer(fptr,delimiter=',')\n",
    "writer.writerow(head)\n",
    "    \n",
    "    \n",
    "N=100\n",
    "x0=0.5*np.random.randn(2,N)\n",
    "\n",
    "fig = plt.figure()  #  axis([-10 10 -10 10]),hold on;\n",
    "ax0 = fig.add_subplot(1,1,1)\n",
    "ax0.set_xlim(-10., 10.)\n",
    "ax0.set_ylim(-10., 10.)\n",
    "\n",
    "x1=np.zeros((2,N))\n",
    "x2=np.zeros((2,N))\n",
    "x3=np.zeros((2,N))\n",
    "\n",
    "for j in range(N):\n",
    "   x1[:,j] = x0[:,j] + [-1,1]\n",
    "   x2[:,j] = x0[:,j] + [2,3]\n",
    "   x3[:,j] = x0[:,j] + [2,6]\n",
    "#\n",
    "#\n",
    "ax0.plot(x1[0,:],x1[1,:],'r+')\n",
    "ax0.plot(x2[0,:],x2[1,:],'bo')\n",
    "ax0.plot(x3[0,:],x3[1,:],'g*')\n",
    "\n",
    "\n",
    "for j in range(N):\n",
    "   writer.writerow([x1[0,j],x1[1,j],'1'])\n",
    "for j in range(N):\n",
    "   writer.writerow([x2[0,j],x2[1,j],'2'])\n",
    "for j in range(N):\n",
    "   writer.writerow([x3[0,j],x3[1,j],'3'])\n",
    "\n",
    "\n",
    "fptr.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pre-processing\n",
    "\n",
    "First we split the data into 70-30 partition (with shuffling, so random_state=1). \n",
    "\n",
    "Let X and y (respectively) denote the training and testing partition, and recall that we must normalize the data by using StandardScaler().Transform(X) function.\n",
    "\n",
    "Since the sample size far exceeds 30, and assuming independence, CLT will apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(filename, names=[\"X1\", \"X2\", \"Class\"], header=0)\n",
    "X = df.iloc[:,0:2]\n",
    "y = df.iloc[:,2]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
